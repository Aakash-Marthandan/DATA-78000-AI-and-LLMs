{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S7mv6l7BBGiC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a48d07b7-78b7-4150-ed7c-8b1417e79175"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import re\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk import word_tokenize\n",
        "from nltk import sent_tokenize\n",
        "\n",
        "from nltk.util import bigrams\n",
        "from nltk.lm.preprocessing import padded_everygram_pipeline\n",
        "\n",
        "import requests"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# you will need to leverage the requests package\n",
        "r = requests.get(r'https://www.gutenberg.org/cache/epub/64317/pg64317.txt')\n",
        "great_gatsby = r.text\n",
        "\n",
        "# first, remove unwanted new line and tab characters from the text\n",
        "for char in [\"\\n\", \"\\r\", \"\\d\", \"\\t\"]:\n",
        "    great_gatsby = great_gatsby.replace(char, \" \")\n",
        "\n",
        "# check\n",
        "print(great_gatsby[:100])\n",
        "# remove the metadata at the beginning - this is slightly different for each book\n",
        "great_gatsby = great_gatsby[983:]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "040R_jVFBP28",
        "outputId": "f6f4c98d-3cbd-41fc-9fcf-e5dde3e48f2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "﻿The Project Gutenberg eBook of The Great Gatsby        This ebook is for the use of anyone anywhere\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# this is simplified for demonstration\n",
        "def sample_clean_text(text: str):\n",
        "    # lowercase\n",
        "    text = text.lower()\n",
        "\n",
        "    # remove punctuation from text\n",
        "    text = re.sub(r\"[^\\w\\s]\", \"\", text)\n",
        "\n",
        "    # tokenize the text\n",
        "    tokens = nltk.word_tokenize(text)\n",
        "\n",
        "    # return your tokens\n",
        "    return tokens\n",
        "\n",
        "# call the function\n",
        "sample_tokens = sample_clean_text(text = great_gatsby)\n",
        "\n",
        "# check\n",
        "print(sample_tokens[:50])\n",
        "# create bigrams from the sample tokens\n",
        "my_bigrams = bigrams(sample_tokens)\n",
        "\n",
        "# check\n",
        "list(my_bigrams)[:10]\n",
        "# 2 is for bigrams\n",
        "n = 2\n",
        "#specify the text you want to use\n",
        "text = great_gatsby\n",
        "# step 1: tokenize the text into sentences\n",
        "sentences = nltk.sent_tokenize(text)\n",
        "\n",
        "# step 2: tokenize each sentence into words\n",
        "tokenized_sentences = [nltk.word_tokenize(sent) for sent in sentences]\n",
        "\n",
        "# step 3: convert each word to lowercase\n",
        "tokenized_text = [[word.lower() for word in sent] for sent in tokenized_sentences]\n",
        "\n",
        "#notice the sentence breaks and what the first 10 items of the tokenized text\n",
        "print(tokenized_text[0])\n",
        "# notice what the first 10 items are of the vocabulary\n",
        "print(text[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U0C-MFRnBh-c",
        "outputId": "073432b3-beb5-4ac4-a084-395f87a0793e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['then', 'wear', 'the', 'gold', 'hat', 'if', 'that', 'will', 'move', 'her', 'if', 'you', 'can', 'bounce', 'high', 'bounce', 'for', 'her', 'too', 'till', 'she', 'cry', 'lover', 'goldhatted', 'highbouncing', 'lover', 'i', 'must', 'have', 'you', 'thomas', 'parke', 'dinvilliers', 'i', 'in', 'my', 'younger', 'and', 'more', 'vulnerable', 'years', 'my', 'father', 'gave', 'me', 'some', 'advice', 'that', 'ive', 'been']\n",
            "['then', 'wear', 'the', 'gold', 'hat', ',', 'if', 'that', 'will', 'move', 'her', ';', 'if', 'you', 'can', 'bounce', 'high', ',', 'bounce', 'for', 'her', 'too', ',', 'till', 'she', 'cry', '“', 'lover', ',', 'gold-hatted', ',', 'high-bouncing', 'lover', ',', 'i', 'must', 'have', 'you', '!', '”', 'thomas', 'parke', 'd', '’', 'invilliers', 'i', 'in', 'my', 'younger', 'and', 'more', 'vulnerable', 'years', 'my', 'father', 'gave', 'me', 'some', 'advice', 'that', 'i', '’', 've', 'been', 'turning', 'over', 'in', 'my', 'mind', 'ever', 'since', '.']\n",
            " Then wear\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# we imported this function from nltk\n",
        "train_data, padded_sents = padded_everygram_pipeline(n, tokenized_text)\n",
        "from nltk.lm import MLE\n",
        "# we imported this function from nltk linear models (lm)\n",
        "# it is for Maximum Likelihood Estimation\n",
        "\n",
        "# MLE is the model we will use\n",
        "lm = MLE(n)\n",
        "# currently the vocab length is 0: it has no prior knowledge\n",
        "len(lm.vocab)\n",
        "# fit the model\n",
        "# training data is the bigrams and unigrams\n",
        "# the vocab is all the sentence tokens in the corpus\n",
        "\n",
        "lm.fit(train_data, padded_sents)\n",
        "len(lm.vocab)"
      ],
      "metadata": {
        "id": "ld2znZ5lCD-l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3aa245d9-c0f2-48dd-c80e-d0690c6ea815"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6953"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# inspect the model's vocabulary.\n",
        "# be sure that a sentence you know exists (from tokenized_text) is in the\n",
        "print(lm.vocab.lookup(tokenized_text[0]))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XyfL6h4uuBZl",
        "outputId": "ea0e2c51-0442-4dd0-af74-a2144daa20fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('then', 'wear', 'the', 'gold', 'hat', ',', 'if', 'that', 'will', 'move', 'her', ';', 'if', 'you', 'can', 'bounce', 'high', ',', 'bounce', 'for', 'her', 'too', ',', 'till', 'she', 'cry', '“', 'lover', ',', 'gold-hatted', ',', 'high-bouncing', 'lover', ',', 'i', 'must', 'have', 'you', '!', '”', 'thomas', 'parke', 'd', '’', 'invilliers', 'i', 'in', 'my', 'younger', 'and', 'more', 'vulnerable', 'years', 'my', 'father', 'gave', 'me', 'some', 'advice', 'that', 'i', '’', 've', 'been', 'turning', 'over', 'in', 'my', 'mind', 'ever', 'since', '.')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# see what happens when we include a word that is not in the vocab.\n",
        "print(lm.vocab.lookup('then wear the gold hat iphone .'.split()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UcbWyR3DuKLj",
        "outputId": "61eebceb-b1cc-42b2-8229-8cef49260d14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('then', 'wear', 'the', 'gold', 'hat', '<UNK>', '.')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# how many times does daisy appear in the model?\n",
        "print(lm.counts['daisy'])\n",
        "\n",
        "# what is the probability of daisy appearing?\n",
        "# this is technically the relative frequency of daisy appearing\n",
        "lm.score('daisy')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gB1XpGyauKOL",
        "outputId": "0d6ad580-e3f9-4d1a-9b89-f9acaaa9faa8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "183\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0026549057726065954"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# how often does (daisy, and) occur and what is the relative frequency?\n",
        "print(lm.counts[['daisy']]['and'])\n",
        "lm.score('and', 'daisy'.split())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nqIxt4rFuKRH",
        "outputId": "a70d0bcd-3e44-4ea3-ad10-67ebea3f1857"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "14\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.07650273224043716"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# what is the score of 'UNK'?\n",
        "\n",
        "lm.score(\"<UNK>\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GFL0HNNFuKUR",
        "outputId": "61e4d245-30c4-4112-8b87-30b768f1e0e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# generate a 20 word sentence starting with the word, 'daisy'\n",
        "\n",
        "print(lm.generate(20, text_seed= 'daisy', random_seed=42))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W9EoxPKsuKXY",
        "outputId": "0ce96671-b173-4504-9e82-196f523e8c76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['other', ',', 'but', 'he', 'turned', 'to', 'their', 'cars', 'blocking', 'the', 'dull', 'light', ',', 'and', 'separated', 'only', 'building', 'in', 'the', 'adventitious']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
        "\n",
        "detokenize = TreebankWordDetokenizer().detokenize\n",
        "\n",
        "def generate_sent(lm, num_words, text_seed, random_seed=42):\n",
        "    \"\"\"\n",
        "    :param model: An ngram language model from `nltk.lm.model`.\n",
        "    :param num_words: Max no. of words to generate.\n",
        "    :param random_seed: Seed value for random.\n",
        "    \"\"\"\n",
        "    content = []\n",
        "    for token in lm.generate(num_words, text_seed=text_seed, random_seed=random_seed):\n",
        "        if token == '<s>':\n",
        "            continue\n",
        "        if token == '</s>':\n",
        "            break\n",
        "        content.append(token)\n",
        "    return detokenize(content)"
      ],
      "metadata": {
        "id": "8ZqvhR_Cx_4X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now generate sentences that look much nicer.\n",
        "generate_sent(lm, 20, text_seed='daisy', random_seed = 42)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Xb6FlCqCyFH1",
        "outputId": "4dd18936-aade-4ad8-9a65-1a0d57e0541a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'other, but he turned to their cars blocking the dull light, and separated only building in the adventitious'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dn8aQ_NYyFTY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}